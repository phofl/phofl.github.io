<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Patrick Hoefler</title><link href="https://phofl.github.io/" rel="alternate"></link><link href="https://phofl.github.io/feeds/all.atom.xml" rel="self"></link><id>https://phofl.github.io/</id><updated>2023-03-23T00:00:00+01:00</updated><entry><title>Welcoming pandas 2.0</title><link href="https://phofl.github.io/pandas-20.html" rel="alternate"></link><published>2023-03-23T00:00:00+01:00</published><updated>2023-03-23T00:00:00+01:00</updated><author><name>Patrick Hoefler</name></author><id>tag:phofl.github.io,2023-03-23:/pandas-20.html</id><summary type="html">&lt;p&gt;&lt;em&gt;How the API is changing and how to leverage new functionalities&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;After 3 years of development, the second pandas 2.0 release candidate was released on the 16th of 
March. There are many new features in pandas 2.0, including improved extension array
support, pyarrow support for DataFrames and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;How the API is changing and how to leverage new functionalities&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;After 3 years of development, the second pandas 2.0 release candidate was released on the 16th of 
March. There are many new features in pandas 2.0, including improved extension array
support, pyarrow support for DataFrames and non-nanosecond datetime resolution, but also
many enforced deprecations and hence API changes. Before we investigate how new features can improve
your workflow, we take a look at some enforced deprecations.&lt;/p&gt;
&lt;h2 id="api-changes"&gt;API changes&lt;/h2&gt;
&lt;p&gt;The 2.0 release is a major release for pandas (check out the 
&lt;a href="https://pandas.pydata.org/docs/development/policies.html#version-policy"&gt;versioning policy&lt;/a&gt;), 
hence all deprecations added in the 1.x series were enforced.
There were around 150 different warnings in the latest 1.5.3 release. If your code runs without
warnings on 1.5.3, you should be good to go on 2.0. We will have a quick look at some
subtle or more noticeable deprecations before jumping into new features. You can check out the
complete release notes &lt;a href="https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="index-now-supports-arbitrary-numpy-dtypes"&gt;Index now supports arbitrary NumPy dtypes&lt;/h3&gt;
&lt;p&gt;Before the 2.0 release, an &lt;code&gt;Index&lt;/code&gt; only supported &lt;code&gt;int64&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt; and &lt;code&gt;uint64&lt;/code&gt; dtypes 
which resulted in an &lt;code&gt;Int64Index&lt;/code&gt;, &lt;code&gt;Float64Index&lt;/code&gt; or &lt;code&gt;UInt64Index&lt;/code&gt;. These classes where 
removed. All numeric indexes are now represented as &lt;code&gt;Index&lt;/code&gt; with an associated dtype, e.g.:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;In [1]: pd.Index([1, 2, 3], dtype=&amp;quot;int64&amp;quot;)
Out[1]: Index([1, 2, 3], dtype='int64')
In [2]: pd.Index([1, 2, 3], dtype=&amp;quot;int32&amp;quot;)
Out[2]: Index([1, 2, 3], dtype='int32')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This mirrors the behavior for extension array backed Indexes. An Index can hold arbitrary extension 
array dtypes since pandas 1.4.0. You can check the 
&lt;a href="https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html#index-can-now-hold-numpy-numeric-dtypes"&gt;release notes&lt;/a&gt; 
for further information. This change is only noticeable when an explicit Index subclass, that no
longer exists, is used.&lt;/p&gt;
&lt;h3 id="behavior-change-in-numeric_only-for-aggregation-functions"&gt;Behavior change in &lt;code&gt;numeric_only&lt;/code&gt; for aggregation functions&lt;/h3&gt;
&lt;p&gt;In previous versions you could call aggregation functions on a DataFrame with mixed-dtypes and
got varying results. Sometimes the aggregation worked and excluded non-numeric dtypes, in some
other cases an error was raised. The &lt;code&gt;numeric_only&lt;/code&gt; argument is now consistent and the aggregation
will raise if you apply it on a DataFrame with non-numeric dtypes. You can set &lt;code&gt;numeric_only&lt;/code&gt;
to &lt;code&gt;True&lt;/code&gt; or restrict your DataFrame to numeric columns, if you want to get the same behavior
as before. This will avoid accidentally dropping relevant columns from the &lt;code&gt;DataFrame&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Calculating the mean over a DataFrame dropped non-numeric columns before 2.0:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;In[2] df = DataFrame({&amp;quot;a&amp;quot;: [1, 2, 3], &amp;quot;b&amp;quot;: [&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;z&amp;quot;]})
In[3] df.mean()
Out[3]: 
a    2.0
dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This operation now raises an error to avoid dropping relevant columns in these aggregations:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;TypeError: Could not convert ['xyz'] to numeric
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="improvements-and-new-features"&gt;Improvements and new features&lt;/h2&gt;
&lt;p&gt;pandas 2.0 brings a some interesting new functionalities like PyArrow-backed DataFrames, 
non-nanosecond resolution/accuracy for timestamps and many Copy-on-Write improvements. Let's take
a closer look at some of those now.&lt;/p&gt;
&lt;h3 id="improved-support-for-nullable-dtypes-and-extension-arrays"&gt;Improved support for nullable dtypes and extension arrays&lt;/h3&gt;
&lt;p&gt;The 2.0 release brings a vast improvement for nullable dtypes and extension arrays in general.
Internally, many operations now use nullable semantics instead of casting to object when
using nullable dtypes like &lt;code&gt;Int64&lt;/code&gt;, &lt;code&gt;boolean&lt;/code&gt; or &lt;code&gt;Float64&lt;/code&gt;. The internal handling of extension
arrays got consistently better over the 1.x series. This is visible through
a bunch of significant performance improvements:&lt;/p&gt;
&lt;p&gt;On pandas 2.0:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;In[3]: ser = pd.Series(list(range(1, 1_000_000)) + [pd.NA], dtype=&amp;quot;Int64&amp;quot;)
In[4]: %timeit ser.drop_duplicates()
7.54 ms ± 24 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On pandas 1.5.3:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;In[3]: ser = pd.Series(list(range(1, 1_000_000)) + [pd.NA], dtype=&amp;quot;Int64&amp;quot;)
In[4]: %timeit ser.drop_duplicates()
22.7 ms ± 272 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Additionally, many operations now properly operate on the nullable arrays which maintains the
appropriate dtype when returning the result. All groupby algorithms now use nullable semantics,
which results in better accuracy (previously the input was cast to float which might have let
to a loss of precision) and performance improvements.&lt;/p&gt;
&lt;p&gt;To improve opting into nullable dtypes, a new keyword &lt;code&gt;dtype_backen&lt;/code&gt; which returns
a &lt;code&gt;DataFrame&lt;/code&gt; completely backed by nullable dtypes when set to &lt;code&gt;"numpy_nullable"&lt;/code&gt; was added to 
most I/O functions. In addition to using nullable dtypes for numeric columns, 
this option results in a &lt;code&gt;DataFrame&lt;/code&gt; that uses the pandas &lt;code&gt;StringDtype&lt;/code&gt;
instead of a NumPy array with dtype &lt;code&gt;object&lt;/code&gt;. Based on the storage option, the string columns
are either backed by Python strings or by PyArrow strings. The PyArrow alternative is generally
faster than the Python strings.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Index&lt;/code&gt; and &lt;code&gt;MultiIndex&lt;/code&gt; classes are now better integrated with extension
arrays in general. General Extension Array support was introduced in 1.4. A quick overview of what
this entails:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using extension array semantics for operations on the index&lt;/li&gt;
&lt;li&gt;Efficient Indexing operations on nullable and pyarrow dtypes&lt;/li&gt;
&lt;li&gt;No materialization of MultiIndexes to improve performance and maintain dtypes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Extension Array interface is continuously improving and continues to avoid materializing NumPy 
arrays and instead relies on the provided extension array implementation in a growing number
of methods. Some areas are still under development, including GroupBy aggregations for third party 
extension arrays.&lt;/p&gt;
&lt;h3 id="pyarrow-backed-dataframes"&gt;Pyarrow-backed DataFrames&lt;/h3&gt;
&lt;p&gt;Version 1.5.0 brought a new extension array to pandas that enables users to create &lt;code&gt;DataFrames&lt;/code&gt;
backed by PyArrow arrays. We expect these extension arrays to provide a vast improvement when
operating on string-columns, since the NumPy object representation is not very efficient. The
string representation is mostly equivalent to&lt;code&gt;string[pyarrow]&lt;/code&gt; that has been around for quite some 
time. The PyArrow-specific extension array supports all other PyArrow dtypes on top of it. Users can 
now create columns with any PyArrow dtype and/or use PyArrow nullable semantics. Those
come out of the box when using PyArrow dtypes. A PyArrow-backed column can be requested 
specifically by casting to or specifying a column's dtype as &lt;code&gt;f"{dtype}[pyarrow]"&lt;/code&gt;, e.g. 
&lt;code&gt;"int64[pyarrow]"&lt;/code&gt; for an integer column. Alternatively, a PyArrow dtype can be created through:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;import pandas as pd
import pyarrow as pa

dtype = pd.ArrowDtype(pa.int64)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The API in 1.5.0 was pretty raw and experimental and fell back to NumPy quite often. With pandas 2.0 and an 
increased minimum version of PyArrow (7.0 for pandas 2.0), we can now utilize the corresponding PyArrow compute 
functions in many more methods. This improves performance significantly and gets rid of many
&lt;code&gt;PerformanceWarnings&lt;/code&gt; that were raised before when falling back to NumPy. Similarly to the
nullable dtypes, most I/O methods can return PyArrow-backed DataFrames through the keyword
&lt;code&gt;dtype_backend="pyarrow"&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Future versions of pandas will bring many more improvements in this area!&lt;/p&gt;
&lt;p&gt;Some I/O methods have specific PyArrow engines, like &lt;code&gt;read_csv&lt;/code&gt; and &lt;code&gt;read_json&lt;/code&gt;, which bring
a significant performance improvement when requesting PyArrow-backed &lt;code&gt;DataFrames&lt;/code&gt;. They don't 
support all options that the original implementations support yet. Check out a more &lt;a href="https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i"&gt;in-depth
exploration&lt;/a&gt; from Marc 
Garcia.&lt;/p&gt;
&lt;h3 id="non-nanosecond-resolution-in-timestamps"&gt;Non-nanosecond resolution in Timestamps&lt;/h3&gt;
&lt;p&gt;A long-standing issue in pandas was that timestamps were always represented in nanosecond 
resolution. As a consequence, there was no way of representing dates before the 1st of January
1970 or after the 11th of April 2264. This caused pains in the research community when analyzing
timeseries data that spanned over millennia and more.&lt;/p&gt;
&lt;p&gt;The 2.0 release introduces support for other resolutions, e.g. support for second, millisecond
and microsecond resolution was added. This enables time ranges up to &lt;code&gt;+/- 2.9e11 years&lt;/code&gt; and thus 
should cover most common use-cases.&lt;/p&gt;
&lt;p&gt;On previous versions, passing a date to the &lt;code&gt;Timestamp&lt;/code&gt; constructor that was out of the supported
range raised an error no matter what unit was specified. With pandas 2.0 the unit is honored, and
thus you can create arbitrary dates:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;In[5]: pd.Timestamp(&amp;quot;1000-10-11&amp;quot;, unit=&amp;quot;s&amp;quot;)
Out[5]: Timestamp('1000-10-11 00:00:00')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The timestamp is only returned up to the second, higher precisions are not supported when specifying
&lt;code&gt;unit="s"&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Support for non-nanosecond resolutions of timestamps is still actively developed. Many
methods relied on the assumption that a timestamp was always given in nanosecond resolution. It is
a lot of work to get rid of these problems everywhere and hence you might still encounter some
bugs in different areas.&lt;/p&gt;
&lt;h3 id="copy-on-write-improvements"&gt;Copy-on-Write improvements&lt;/h3&gt;
&lt;p&gt;Copy-on-Write (CoW) was originally introduced in pandas 1.5.0. Check out my initial post introducing
&lt;a href="https://phofl.github.io/cow-introduction.html"&gt;Copy-on-Write&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Short summary:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Any DataFrame or Series derived from another in&lt;/strong&gt; 
&lt;strong&gt;any way always behaves as a copy&lt;/strong&gt;. As a consequence, we can only change the values of an object 
through modifying the object itself. CoW disallows updating a DataFrame or a Series that shares 
data with another DataFrame or Series object inplace.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Version 1.5 provided the general mechanism but not much apart from that. A couple of bugs where 
Copy-on-Write was not respected, and hence two objects could get modified with one operation, were
discovered and fixed since then.&lt;/p&gt;
&lt;p&gt;More importantly, nearly all methods now utilize a &lt;em&gt;lazy copy&lt;/em&gt; mechanism to avoid copying the
underlying data as long as possible. Without CoW enabled, most methods perform defensive copies 
to avoid side effects when an object is modified later on. This results in high memory usage and a
relatively high runtime. Copy-on-Write enables us to remove all defensive copies and defer
the actual copies until the data of an object are modified.&lt;/p&gt;
&lt;p&gt;Additionally, CoW provides a cleaner and easier to work with API and should give your code a
performance boost on top of it. Generally, if an application does not rely on updating more than one object at
once and does not utilize chained assignment, the risk of turning Copy-on-Write 
on is minor. I've tested it on some code-bases and saw promising performance improvements, so I'd recommend
trying it out to see how it impacts your code. We are currently planning on making CoW the default in the next
major release. I'd recommend developing new features with Copy-on-Write enabled
to avoid migration issues later on.&lt;/p&gt;
&lt;p&gt;A PDEP (pandas development enhancement proposal) was submitted to deprecate and remove the
&lt;code&gt;inplace&lt;/code&gt; and &lt;code&gt;copy&lt;/code&gt; keyword in most methods. Those would become obsolete with Copy-on-Write
enabled and would only add confusion for users. You can follow this discussion 
&lt;a href="https://github.com/pandas-dev/pandas/pull/51466"&gt;here&lt;/a&gt;. If accepted, the removal of both keywords
will happen when CoW is made the default.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;pandas 2.0 brings many new and exiting features. We've seen a couple of them and looked at how
to utilize them. &lt;/p&gt;
&lt;p&gt;Thank you for reading. Feel free to reach out in the comments to share your thoughts and feedback 
on the 2.0 release. I will write additional posts focusing on Copy-on-Write and how to get the
most out of it. Follow me on Medium if you like to read more about pandas in general.&lt;/p&gt;</content><category term="posts"></category><category term="pandas"></category></entry><entry><title>A guide to efficient data selection in pandas</title><link href="https://phofl.github.io/indexing-copy-view.html" rel="alternate"></link><published>2023-02-10T00:00:00+01:00</published><updated>2023-02-10T00:00:00+01:00</updated><author><name>Patrick Hoefler</name></author><id>tag:phofl.github.io,2023-02-10:/indexing-copy-view.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Improve performance when selecting data from a pandas object&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;There exist different ways of selecting a subset of data from a pandas object. Depending
on the specific operation, the result will either be a view pointing to the original
data or a copy of the original data. This ties …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Improve performance when selecting data from a pandas object&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;There exist different ways of selecting a subset of data from a pandas object. Depending
on the specific operation, the result will either be a view pointing to the original
data or a copy of the original data. This ties directly to the efficiency of the operation. 
The copy and view rules are partially derived from the 
&lt;a href="https://numpy.org/doc/stable/user/basics.indexing.html"&gt;NumPy advanced indexing rules&lt;/a&gt;.
We will look at different operations and how to improve performance and efficiency as much as 
possible. &lt;a href="https://github.com/phofl"&gt;I am&lt;/a&gt; a member of the pandas core team.&lt;/p&gt;
&lt;p&gt;We will also investigate how 
&lt;a href="https://medium.com/towards-data-science/a-solution-for-inconsistencies-in-indexing-operations-in-pandas-b76e10719744"&gt;Copy on Write&lt;/a&gt; 
will change the behavior for some operations to improve performance and avoid copies as much as 
possible.&lt;/p&gt;
&lt;h2 id="dataset"&gt;Dataset&lt;/h2&gt;
&lt;p&gt;We will use a dataset that contains all players from FIFA 2021. You can download the
dataset &lt;a href="https://www.kaggle.com/datasets/stefanoleone992/fifa-21-complete-player-dataset"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;import pandas as pd

df = pd.read_csv(&amp;quot;players_21.csv&amp;quot;, index_col=&amp;quot;team_position&amp;quot;).sort_index()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We set each player's position as index and sort the &lt;code&gt;DataFrame&lt;/code&gt; by it.
This will allow faster and easier access to the players by position and will help us to
illustrate a few examples.&lt;/p&gt;
&lt;h2 id="selecting-a-subset-of-rows"&gt;Selecting a subset of rows&lt;/h2&gt;
&lt;p&gt;We start by selecting players by position from our dataset. There are a couple of ways to achieve
this. The most common might be selecting by a boolean mask. We can calculate the boolean mask 
to select all players with position &lt;code&gt;"LS"&lt;/code&gt; through:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;mask = df.index == &amp;quot;LS&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Afterwards, we can extract the rows from our DataFrame by:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;result1 = df[mask]
result2 = df.loc[mask]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both operations achieve the same result in this case. We will investigate the differences
when looking at modifying our DataFrame.&lt;/p&gt;
&lt;p&gt;Selecting rows by a boolean mask &lt;strong&gt;always&lt;/strong&gt; creates a copy of the data. Depending on the
size of your dataset, this might cause a significant slowdown. Alternatively, we can select the
data by slicing the object:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;result = df.loc[&amp;quot;LS&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Slicing the object creates a view on the underlying data, which thus makes your operation
significantly faster. You can also select every second/n-th row by:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;result = df.iloc[slice(1, len(df), 2)]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will also create a view pointing to the original object. Getting a view is generally preferable, because
it improves performance and reduces memory usage. On the other hand side, you could also
create a list of integers corresponding with our slice:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;result = df.iloc[list(range(1, len(df), 2))]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Selecting rows by a list of integers will create a copy, even though the operation look similar and
returns exactly the same data. This is again derived from NumPy's indexing rules.&lt;/p&gt;
&lt;p&gt;Slicing has many applications, for example
by integer position, with a DatetimeIndex or slicing an Index with strings. Selecting data by 
slice, if possible, is significantly faster than with a list of integers or boolean masks.&lt;/p&gt;
&lt;p&gt;Summarizing, depending on your use case, you may be able to significantly improve performance
when selecting rows. Setting an appropriate index might make your operations easier to
read and more efficient. &lt;/p&gt;
&lt;h2 id="selecting-a-subset-of-columns"&gt;Selecting a subset of columns&lt;/h2&gt;
&lt;p&gt;There are generally two cases to consider when selecting columns from your DataFrame:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;selecting a single column&lt;/li&gt;
&lt;li&gt;selecting multiple columns&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Selecting a single column is relatively straightforward, you can either use a regular &lt;strong&gt;getitem&lt;/strong&gt;
or &lt;code&gt;loc&lt;/code&gt; for this. There is no substantial difference for a single column when selecting data, 
only when we want to update said data.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;result = df[&amp;quot;long_name&amp;quot;]
result = df.loc[:, &amp;quot;long_name&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As soon as an iterable is passed to one of both calls, or if the selected column is duplicated,
we get a DataFrame back, but a copy of the underlying data is made, e.g.:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;result = df.loc[:, [&amp;quot;short_name&amp;quot;, &amp;quot;long_name&amp;quot;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Selecting more than one column generally makes a copy right now. All these operations will return
views when &lt;code&gt;Copy-on-Write&lt;/code&gt; is enabled. This will improve performance significantly for lager 
objects.&lt;/p&gt;
&lt;h2 id="assigning-data-to-a-subset-of-the-dataframe"&gt;Assigning data to a subset of the DataFrame&lt;/h2&gt;
&lt;p&gt;Let's look at how to update a subset of your DataFame efficiently. There are two general 
possibilities: A regular &lt;strong&gt;setitem&lt;/strong&gt; or using &lt;code&gt;loc&lt;/code&gt; / &lt;code&gt;iloc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;When adding a new column to a DataFrame, I would suggest using a regular &lt;strong&gt;setitem&lt;/strong&gt; operation.
It is shorter and a bit easier to read. There is no substantial difference in both operations, e.g.:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df[&amp;quot;new_column&amp;quot;] = 100
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is a substantial difference when updating a DataFrame though. Assume we want to set the
name for all players with position &lt;code&gt;"LS"&lt;/code&gt; in our object. A regular &lt;strong&gt;setitem&lt;/strong&gt; operation 
&lt;strong&gt;never&lt;/strong&gt; writes into the underlying array. The data of this column are copied before the update 
happens. Also, there is no way of updating a subset of a specific row in one operation. You'd have
to use chained assignment, which has its own pitfalls. We will investigate them later. &lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;long_name = df[[&amp;quot;long_name&amp;quot;]]
long_name[long_name.index == &amp;quot;LS&amp;quot;] = &amp;quot;Testname&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are copying the whole column before updating all rows that have index &lt;code&gt;"LS"&lt;/code&gt; inplace. This
is significantly slower that using &lt;code&gt;loc&lt;/code&gt; / &lt;code&gt;iloc&lt;/code&gt;. Both methods update the underlying array
inplace if possible. Additionally, we don't have to use a boolean mask to achieve this.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df.loc[&amp;quot;LS&amp;quot;, &amp;quot;long_name&amp;quot;] = &amp;quot;Testname&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In general, &lt;code&gt;iloc&lt;/code&gt; is more efficient than &lt;code&gt;loc&lt;/code&gt;. The downside is, that you already have to
know the positions where you want to insert your new values. But if you want to update a specific
set of rows, using &lt;code&gt;iloc&lt;/code&gt; is more efficient than &lt;code&gt;loc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Setting values inplace without making a copy only works, if the dtype of the value/values to
set is compatible with the dtype of the underlying array. For example, setting integer values into
a float or object dtype column generally operates inplace. Setting a float value into an integer dtype
column has to copy the data as well. An integer column can't hold a float value, and hence the
data have to be cast into a dtype that can hold both values. As a side-note: There is an ongoing 
&lt;a href="https://github.com/pandas-dev/pandas/pull/50424"&gt;discussion&lt;/a&gt;
about deprecating this behavior and raise an error, if an incompatible value is set into a column. It
would require casting the column explicitly to float before setting the values. Feedback on this
proposal is welcome!&lt;/p&gt;
&lt;p&gt;There is one specific exception: When overwriting a whole column, using a regular &lt;strong&gt;setitem&lt;/strong&gt;
is generally faster than using &lt;code&gt;loc&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df[&amp;quot;long_name&amp;quot;] = &amp;quot;Testname&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The reason for this is pretty simple: &lt;code&gt;loc&lt;/code&gt; writes into the underlying array, which means that
you have to update every row for this column. The above operation simply swaps out the old column 
and adds the new column to the object without copying anything.&lt;/p&gt;
&lt;h2 id="chained-assignment"&gt;Chained assignment&lt;/h2&gt;
&lt;p&gt;Chained assignment describes doing two indexing operations with one statement and then assigning
data to the selected subset, e.g.:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df[&amp;quot;long_name&amp;quot;][df.index == &amp;quot;LS&amp;quot;] = &amp;quot;Testname&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This operation updates the DataFrame accordingly. In general, chained assignment shouldn't be
used, because it is the frequent culprit behind the &lt;code&gt;SettingWithCopyWarning&lt;/code&gt;. Additionally,
chained assignment will raise an error with copy on write enabled globally or as soon as 
copy on write becomes the default.&lt;/p&gt;
&lt;h2 id="performance-comparison"&gt;Performance comparison&lt;/h2&gt;
&lt;p&gt;Let's look at what this means performance-wise. This is just meant as a quick example to
show how to improve the efficiency of your data selections through avoiding copies. You'll have to 
tailor this to your application. &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;iloc&lt;/code&gt; are really flexible, so use-cases
will vary a lot. &lt;/p&gt;
&lt;p&gt;We need larger DataFrames
to avoid noise in our operations. We instantiate a DataFrame with random numbers:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;import numpy as np

df = pd.DataFrame(
    np.random.randint(1, 100, (1_000_000, 30)), 
    columns=[f&amp;quot;col_{i}&amp;quot; for i in range(30)],
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let's look what slicing vs. selecting a list of integers means performance-wise:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;%timeit df.loc[slice(10_000, 900_000)]
9.61 µs ± 493 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)
%timeit df.loc[list(range(10_000, 900_000))]
68.2 ms ± 465 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a pretty significant difference for a small change to your code.
Using &lt;code&gt;iloc&lt;/code&gt; shows the same difference.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;You can speed up your data selection and data modification methods through choosing the
best method for your operation. Generally, using a slice to select rows from a DataFrame is
significantly faster than using a boolean mask or a list of integers. When setting values, you
have to be careful to use compatible values. Additionally, we can improve performance by using
&lt;code&gt;loc&lt;/code&gt; or &lt;code&gt;iloc&lt;/code&gt;, if we don't have a problem with modifying the underlying array.&lt;/p&gt;</content><category term="posts"></category><category term="pandas"></category></entry><entry><title>A solution for inconsistencies in indexing operations in pandas</title><link href="https://phofl.github.io/cow-introduction.html" rel="alternate"></link><published>2022-12-23T00:00:00+01:00</published><updated>2022-12-23T00:00:00+01:00</updated><author><name>Patrick Hoefler</name></author><id>tag:phofl.github.io,2022-12-23:/cow-introduction.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Get rid of annoying SettingWithCopyWarning messages&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Indexing operations in pandas are quite flexible and thus, have many cases that can behave quite 
different and therefore produce unexpected results. Additionally, it is hard to predict when a 
&lt;code&gt;SettingWithCopyWarningis&lt;/code&gt; raised and what this means exactly. I’ll show a couple of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Get rid of annoying SettingWithCopyWarning messages&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Indexing operations in pandas are quite flexible and thus, have many cases that can behave quite 
different and therefore produce unexpected results. Additionally, it is hard to predict when a 
&lt;code&gt;SettingWithCopyWarningis&lt;/code&gt; raised and what this means exactly. I’ll show a couple of different 
scenarios and how each operation might impact your code. Afterwards, we will look at a new feature 
called &lt;code&gt;Copy on Write&lt;/code&gt; that helps you to get rid of the inconsistencies and of 
&lt;code&gt;SettingWithCopyWarnings&lt;/code&gt;. We will also investigate how this might impact performance and other 
methods in general.&lt;/p&gt;
&lt;h2 id="indexing-operations"&gt;Indexing operations&lt;/h2&gt;
&lt;p&gt;Let’s look at how indexing operations currently work in pandas. If you are already familiar with 
indexing operations, you can jump to the next section. But be aware, there are many cases with 
different forms of behavior. The exact behavor is hard to predict.&lt;/p&gt;
&lt;p&gt;An operation in pandas produces a copy, when the underlying data of the parent DataFrame and the 
new DataFrame are not shared. A view is an object that does share data with the parent object. A 
modification to the view can potentially impact the parent object.&lt;/p&gt;
&lt;p&gt;As of right now, some indexing operations return copies while others return views. The exact 
behavior is hard to predict, even for experienced users. This has been a big annoyance for me in 
the past.&lt;/p&gt;
&lt;p&gt;Let’s start with a DataFrame with two columns:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = pd.DataFrame({&amp;quot;user_id&amp;quot;: [1, 2, 3], &amp;quot;score&amp;quot;: [10, 15, 20]})

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A &lt;strong&gt;getitem&lt;/strong&gt; operation on a DataFrame or Series returns a subset of the initial object. The subset 
might consist of one or a set of columns, one or a set of rows or a mixture of both. A &lt;strong&gt;setitem&lt;/strong&gt; 
operation on a DataFrame or Series updates a subset of the initial object. The subset itself is 
defined by the arguments to the calls.&lt;/p&gt;
&lt;p&gt;A regular &lt;strong&gt;getitem&lt;/strong&gt; operation on a DataFrame provides a view in most cases:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;view = df[&amp;quot;user_id&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a consequence, the new object &lt;code&gt;view&lt;/code&gt; still references the parent object &lt;code&gt;df&lt;/code&gt; and its data. Hence, 
writing into the view will also modify the parent object.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;view.iloc[0] = 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;strong&gt;setitem&lt;/strong&gt; operation will consequently update not only our &lt;code&gt;view&lt;/code&gt; but also &lt;code&gt;df&lt;/code&gt;. This 
happens because the underlying data are shared between both objects.&lt;/p&gt;
&lt;p&gt;This is only true, if the column &lt;code&gt;user_id&lt;/code&gt; occurs only once in &lt;code&gt;df&lt;/code&gt;. As soon as &lt;code&gt;user_id&lt;/code&gt; is 
duplicated the &lt;strong&gt;getitem&lt;/strong&gt; operation returns a DataFrame. This means the returned object is a copy 
instead of a view:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = pd.DataFrame(
    [[1, 10, 2], [3, 15, 4]], 
    columns=[&amp;quot;user_id&amp;quot;, &amp;quot;score&amp;quot;, &amp;quot;user_id&amp;quot;],
)
not_a_view = df[&amp;quot;user_id&amp;quot;]
not_a_view.iloc[0] = 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;setitem&lt;/strong&gt; operation does not update &lt;code&gt;df&lt;/code&gt;. We also get our first &lt;code&gt;SettingWithCopyWarning&lt;/code&gt;, even 
though this is a perfectly acceptable operation. The &lt;strong&gt;getitem&lt;/strong&gt; operation itself has many more cases, 
like list-like keys, e.g. &lt;code&gt;df[["user_id"]]&lt;/code&gt;, MultiIndex-columns and many more. I will go into more 
detail in follow-up posts to look at different forms of performing indexing operations and their 
behavior.&lt;/p&gt;
&lt;p&gt;Let’s have a look at another case that is a bit more complicated than a single &lt;strong&gt;getitem&lt;/strong&gt; operation: 
chained indexing. Chained indexing means filtering with a boolean mask followed by a &lt;strong&gt;getitem&lt;/strong&gt; 
operation or the other way around. This is done in one step. We do not create a new variable to 
store the result of the first operation.&lt;/p&gt;
&lt;p&gt;We again start with a regular DataFrame:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = pd.DataFrame({&amp;quot;user_id&amp;quot;: [1, 2, 3], &amp;quot;score&amp;quot;: [10, 15, 20]})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can update all &lt;code&gt;user_ids&lt;/code&gt; that have a score greater than 15 through:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df[&amp;quot;user_id&amp;quot;][df[&amp;quot;score&amp;quot;] &amp;gt; 15] = 5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We take the column &lt;code&gt;user_id&lt;/code&gt; and apply the filter afterwards. This works perfectly fine, because 
the column selection creates a view and the &lt;strong&gt;setitem&lt;/strong&gt; operation updates said view. We can switch 
both operations as well:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df[df[&amp;quot;score&amp;quot;] &amp;gt; 15][&amp;quot;user_id&amp;quot;] = 5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This execution order produces another &lt;code&gt;SettingWithCopyWarning&lt;/code&gt;. In contrast to our earlier example, 
nothing happens. The DataFrame &lt;code&gt;df&lt;/code&gt; is not modified. This is a silent no-operation. The boolean 
mask always creates a copy of the initial DataFrame. Hence, the initial &lt;strong&gt;getitem&lt;/strong&gt; operation returns 
a copy. The return value is not assigned to any variable and is only a temporary result. The 
setitem operation updates this temporary copy. As a result, the modification is lost. The fact 
that masks return copies while column selections return views is an implementation detail. 
Ideally, such implementation details should not be visible.&lt;/p&gt;
&lt;p&gt;Another approach of doing this is as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;new_df = df[df[&amp;quot;score&amp;quot;] &amp;gt; 15]
new_df[&amp;quot;user_id&amp;quot;] = 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This operation updates &lt;code&gt;new_df&lt;/code&gt; as intended but shows a &lt;code&gt;SettingWithCopyWarning&lt;/code&gt; anyway, because we 
can not update &lt;code&gt;df&lt;/code&gt;. Most of us probably never want to update the initial object (e.g. &lt;code&gt;df&lt;/code&gt;) in this 
scenario, but we get the warning anyway. In my experience this leads to unnecessary copy statements 
scattered over the code base.&lt;/p&gt;
&lt;p&gt;This is just a small sample of current inconsistencies and annoyances in indexing operations.&lt;/p&gt;
&lt;p&gt;Since the actual behavior is hard to predict, this forces many defensive copies in other methods. 
For example,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dropping of columns&lt;/li&gt;
&lt;li&gt;setting a new index&lt;/li&gt;
&lt;li&gt;resetting the index&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All copy the underlying data. These copies are not necessary from an implementation perspective. 
The methods could return views pretty easily, but returning views would lead to unpredictable 
behavior later on. Theoretically, one &lt;strong&gt;setitem&lt;/strong&gt; operation could propagate through the whole 
call-chain, updating many DataFrames at once.&lt;/p&gt;
&lt;h2 id="copy-on-write"&gt;Copy on Write&lt;/h2&gt;
&lt;p&gt;Let’s look at how a new feature called “Copy on Write” (CoW) helps us to get rid of these 
inconsistencies in our code base. CoW means that &lt;strong&gt;any DataFrame or Series derived from another in&lt;/strong&gt; 
&lt;strong&gt;any way always behaves as a copy&lt;/strong&gt;. As a consequence, we can only change the values of an object 
through modifying the object itself. CoW disallows updating a DataFrame or a Series that shares 
data with another DataFrame or Series object inplace. With this information, we can again look at 
our initial example:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = pd.DataFrame({&amp;quot;user_id&amp;quot;: [1, 2, 3], &amp;quot;score&amp;quot;: [10, 15, 20]})
view = df[&amp;quot;user_id&amp;quot;]
view.iloc[0] = 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;getitem&lt;/strong&gt; operation provides a view onto &lt;code&gt;df&lt;/code&gt; and it’s data. The &lt;strong&gt;setitem&lt;/strong&gt; operation triggers a copy 
of the underlying data before &lt;code&gt;10&lt;/code&gt; is written into the first row. Hence, the operation won't modify 
&lt;code&gt;df&lt;/code&gt;. An advantage of this behavior is, that we don’t have to worry about &lt;code&gt;user_id&lt;/code&gt; being potentially
duplicated or using &lt;code&gt;df[["user_id"]]&lt;/code&gt; instead of &lt;code&gt;df["user_id"]&lt;/code&gt;. All these cases behave exactly the 
same and no annoying warning is shown.&lt;/p&gt;
&lt;p&gt;Triggering a copy before updating the values of the object has performance implications. This 
will most certainly cause a small slowdown for some operations. On the other side, a lot of other 
operations can &lt;strong&gt;avoid&lt;/strong&gt; defensive copies and thus improve performance tremendously. The following 
operations can all return views with CoW:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dropping columns&lt;/li&gt;
&lt;li&gt;setting a new index&lt;/li&gt;
&lt;li&gt;resetting the index&lt;/li&gt;
&lt;li&gt;and many more.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s consider the following DataFrame:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;na = np.array(np.random.rand(1_000_000, 100))
cols = [f&amp;quot;col_{i}&amp;quot; for i in range(100)]
df = pd.DataFrame(na, columns=cols)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using &lt;code&gt;add_prefix&lt;/code&gt; adds the given string (e.g. &lt;code&gt;test&lt;/code&gt;) to the beginning of every column name:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df.add_prefix(&amp;quot;test&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Without CoW, this will copy the data internally. This is not necessary when looking solely at the 
operation. But since returning a view can have side effects, the method returns a copy. As a 
consequence, the operation itself is pretty slow:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;482 ms ± 3.43 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This takes quite long. We practically only modify 100 string literals without touching the data at 
all. Returning a view provides a significant speedup in this scenario:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;46.4 µs ± 1.04 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The same operation runs multiple orders of magnitude faster. More importantly, the running time of 
&lt;code&gt;add_prefix&lt;/code&gt; is &lt;strong&gt;constant&lt;/strong&gt; when using CoW and does not depend on the size of your DataFrame. This 
operation was run on the main branch of pandas.&lt;/p&gt;
&lt;p&gt;The copy is only necessary, if two different objects share the same underlying data. In the 
example above, &lt;code&gt;view&lt;/code&gt; and &lt;code&gt;df&lt;/code&gt; both reference the same data. If the data is exclusive to one &lt;code&gt;DataFrame&lt;/code&gt; 
object, no copy is needed, we can continue to modify the data inplace:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = pd.DataFrame({&amp;quot;user_id&amp;quot;: [1, 2, 3], &amp;quot;score&amp;quot;: [10, 15, 20]})
df.iloc[0] = 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case the &lt;strong&gt;setitem&lt;/strong&gt; operation will continue to operate inplace without triggering a copy.&lt;/p&gt;
&lt;p&gt;As a consequence, all the different scenarios that we have seen initially have exactly the same 
behavior now. We don’t have to worry about subtle inconsistencies anymore.&lt;/p&gt;
&lt;p&gt;Another case that currently has strange and hard to predict behavior is chained indexing. Chained 
indexing under CoW will &lt;strong&gt;never&lt;/strong&gt; work. This is a direct consequence of the CoW mechanism. The initial 
selection of columns might return a view, but a copy is triggered when we perform the subsequent 
setitem operation. Fortunately, we can easily modify our code to avoid chained indexing:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df[&amp;quot;user_id&amp;quot;][df[&amp;quot;score&amp;quot;] &amp;gt; 15] = 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use &lt;code&gt;loc&lt;/code&gt; to do both operations at once:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df.loc[df[&amp;quot;score&amp;quot;] &amp;gt; 15, &amp;quot;user_id&amp;quot;] = 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Summarizing, every object that we create behaves like a copy of the parent object. We can not 
accidentally update an object other than the one we are currently working with.&lt;/p&gt;
&lt;h2 id="how-to-try-it-out"&gt;How to try it out&lt;/h2&gt;
&lt;p&gt;You can try the CoW feature since pandas 1.5.0. Development is still ongoing, but the general 
mechanism works already.&lt;/p&gt;
&lt;p&gt;You can either set the CoW flag globally through on of the following statements:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;pd.set_option(&amp;quot;mode.copy_on_write&amp;quot;, True)
pd.options.mode.copy_on_write = True
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, you can enable CoW locally with:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;with pd.option_context(&amp;quot;mode.copy_on_write&amp;quot;, True):
    ...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have seen that indexing operations in pandas have many edge cases and subtle differences in 
behavior that are hard to predict. CoW is a new feature aimed at addressing those differences. 
It can potentially impact performance positively or negatively based on what we are trying to do 
with our data. The full proposal for CoW can be found 
&lt;a href="https://docs.google.com/document/d/1ZCQ9mx3LBMy-nhwRl33_jgcvWo9IWdEfxDNQ2thyTb0/edit#heading=h.iexejdstiz8u"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thank you for reading. Feel free to reach out to share your thoughts and feedback 
on indexing and Copy on Write. I will write follow-up posts focused on this topic and pandas in 
general.&lt;/p&gt;</content><category term="posts"></category><category term="pandas"></category></entry></feed>