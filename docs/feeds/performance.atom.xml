<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Patrick Hoefler - performance</title><link href="https://phofl.github.io/" rel="alternate"></link><link href="https://phofl.github.io/feeds/performance.atom.xml" rel="self"></link><id>https://phofl.github.io/</id><updated>2023-08-17T00:00:00+02:00</updated><entry><title>Deep Dive into pandas Copy-on-Write Mode - Part II</title><link href="https://phofl.github.io/cow-deep-dive.html" rel="alternate"></link><published>2023-08-17T00:00:00+02:00</published><updated>2023-08-17T00:00:00+02:00</updated><author><name>Patrick Hoefler</name></author><id>tag:phofl.github.io,2023-08-17:/cow-deep-dive.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Explaining how Copy-on-Write works internally&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://medium.com/gitconnected/welcoming-pandas-2-0-194094e4275b"&gt;pandas 2.0&lt;/a&gt; was released in 
early April and brought many improvements to the new Copy-on-Write (CoW)
mode. The feature is expected to become the default in pandas 3.0, which is scheduled for
April 2024 at the moment. There are no plans for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Explaining how Copy-on-Write works internally&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://medium.com/gitconnected/welcoming-pandas-2-0-194094e4275b"&gt;pandas 2.0&lt;/a&gt; was released in 
early April and brought many improvements to the new Copy-on-Write (CoW)
mode. The feature is expected to become the default in pandas 3.0, which is scheduled for
April 2024 at the moment. There are no plans for a legacy or non-CoW mode.&lt;/p&gt;
&lt;p&gt;This series of posts will explain how Copy-on-Write works internally to help users understand what's 
going on, show how to use it effectively and illustrate how to adapt your code. This will include 
examples on how to leverage the mechanism to get the most efficient performance and also show a 
couple of anti-patterns that will result in unnecessary bottlenecks. I wrote a 
&lt;a href="https://medium.com/towards-data-science/a-solution-for-inconsistencies-in-indexing-operations-in-pandas-b76e10719744"&gt;short introduction&lt;/a&gt;
to Copy-on-Write a couple of months ago.&lt;/p&gt;
&lt;p&gt;I wrote &lt;a href="https://medium.com/better-programming/pandas-internals-explained-545f14a941c1"&gt;a short post&lt;/a&gt; 
that explains the data structure of pandas which will help understand some terminology that is 
necessary for CoW.&lt;/p&gt;
&lt;p&gt;I am part of the pandas core team and was heavily involved in implementing and improving CoW so far. 
I am an open source engineer for &lt;a href="https://www.coiled.io"&gt;Coiled&lt;/a&gt; where I work on Dask, 
including improving the pandas integration and ensuring that Dask is compliant with CoW.&lt;/p&gt;
&lt;h1 id="how-copy-on-write-changes-pandas-behavior"&gt;How Copy-on-Write changes pandas behavior&lt;/h1&gt;
&lt;p&gt;Many of you are probably familiar with the following caveats in pandas:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;import pandas as pd

df = pd.DataFrame({&amp;quot;student_id&amp;quot;: [1, 2, 3], &amp;quot;grade&amp;quot;: [&amp;quot;A&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;D&amp;quot;]})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let's select the grade-column and overwrite the first row with &lt;code&gt;"E"&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;grades = df[&amp;quot;grade&amp;quot;]
grades.iloc[0] = &amp;quot;E&amp;quot;
df

   student_id grade
0           1     E
1           2     C
2           3     D
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, this also updated &lt;code&gt;df&lt;/code&gt; and not only &lt;code&gt;grades&lt;/code&gt;, which has the potential to 
introduce hard to find bugs. CoW will disallow this behavior and ensures that only &lt;code&gt;df&lt;/code&gt; is
updated. We also see a false-positive &lt;code&gt;SettingWithCopyWarning&lt;/code&gt; that doesn't help us here.&lt;/p&gt;
&lt;p&gt;Let's look at a &lt;code&gt;ChainedIndexing&lt;/code&gt; example that is not doing anything:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df[df[&amp;quot;student_id&amp;quot;] &amp;gt; 2][&amp;quot;grades&amp;quot;] = &amp;quot;F&amp;quot;
df

   student_id grade
0           1     A
1           2     C
2           3     D
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We again get a &lt;code&gt;SettingWithCopyWarning&lt;/code&gt; but nothing happens to &lt;code&gt;df&lt;/code&gt; in this example. All these
gotchas come down to copy and view rules in NumPy, which is what pandas uses under the hood. pandas
users have to be aware of these rules and how they apply to pandas DataFrames to understand why
similar code patterns produce different results. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CoW cleans up all these inconsistencies&lt;/strong&gt;. Users can only update one object at a time when CoW is
enabled, e.g. &lt;code&gt;df&lt;/code&gt; would be unchanged in our first example since only &lt;code&gt;grades&lt;/code&gt; is updated at
that time and the second example raises a &lt;code&gt;ChainedAssignmentError&lt;/code&gt; instead of doing nothing.
Generally, it won't be possible to update two objects at once, e.g., every object behaves as it
is a copy of the previous object.&lt;/p&gt;
&lt;p&gt;There are many more of these cases, but going through all of them is not in scope here.&lt;/p&gt;
&lt;h1 id="how-it-works"&gt;How it works&lt;/h1&gt;
&lt;p&gt;Let's look into Copy-on-Write in more detail and highlight some facts that are good to know. This is 
the main part of this post and is fairly technical.&lt;/p&gt;
&lt;p&gt;Copy-on-Write promises that &lt;strong&gt;any DataFrame or Series derived from another in&lt;/strong&gt; 
&lt;strong&gt;any way always behaves as a copy&lt;/strong&gt;. This means that it is not possible to modify more than one
object with a single operation, e.g. our first example above would only modify &lt;code&gt;grades&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A very defensive approach to guarantee this would be to copy the DataFrame and its data in every 
operation, which would avoid views in pandas altogether. This would guarantee CoW semantics but 
also incur a huge performance penalty, so this wasn't a viable option. &lt;/p&gt;
&lt;p&gt;We will now dive into the mechanism that ensures that no two objects are updated with a single
operation &lt;strong&gt;and&lt;/strong&gt; that our data isn't unnecessarily copied. The second part is what makes the
implementation interesting.&lt;/p&gt;
&lt;p&gt;We have to know exactly when to trigger a copy to avoid copies that aren't absolutely necessary.
Potential copies are only necessary if we try to mutate the values of one pandas object without
copying it's data. We have to
trigger a copy, if the data of this object is shared with another pandas object.
This means that we have to keep track of whether one NumPy array is referenced by two DataFrames (generally, we have to be
aware if one NumPy array is referenced by two pandas objects, but I will use the term DataFrame for 
simplicity).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = pd.DataFrame({&amp;quot;student_id&amp;quot;: [1, 2, 3], &amp;quot;grade&amp;quot;: [1, 2, 3]})
df2 = df[:]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This statement creates a DataFrame &lt;code&gt;df&lt;/code&gt; and a view of this DataFrame &lt;code&gt;df2&lt;/code&gt;. View means that
both DataFrames are backed by the same underlying NumPy array. When we look at this with CoW, 
&lt;code&gt;df&lt;/code&gt; has to be aware that &lt;code&gt;df2&lt;/code&gt; references its NumPy array too. This is not sufficient 
though. &lt;code&gt;df2&lt;/code&gt; also has to be aware that &lt;code&gt;df&lt;/code&gt; references its NumPy array. If both objects
are aware that there is another DataFrame referencing the same NumPy array, we can trigger a copy
in case one of them is modified, e.g.:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df.iloc[0, 0] = 100
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;df&lt;/code&gt; is modified inplace here. &lt;code&gt;df&lt;/code&gt; knows that there is another object that references the same data, 
e.g. it triggers a copy. It is not aware which object references the same data, just that there is
another object out there.&lt;/p&gt;
&lt;p&gt;Let's take a look at how we can achieve this. We created an internal class &lt;code&gt;BlockValuesRefs&lt;/code&gt; that
is used to store this information, it points to all DataFrames that reference a given NumPy array. &lt;/p&gt;
&lt;p&gt;There are three different types of operation that can create a DataFrame:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A DataFrame is created from external data, e.g. through &lt;code&gt;pd.DataFrame(...)&lt;/code&gt; or through any
  I/O method.&lt;/li&gt;
&lt;li&gt;A new DataFrame is created through a pandas operation that triggers a copy of the original data,
  e.g. &lt;code&gt;dropna&lt;/code&gt; creates a copy in almost all cases.&lt;/li&gt;
&lt;li&gt;A new DataFrames is created through a pandas operation that &lt;strong&gt;does not&lt;/strong&gt; trigger a copy of the
  original data, e.g. &lt;code&gt;df2 = df.reset_index()&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first two cases are simple. When the DataFrame is created, the NumPy arrays that back it are
connected to a fresh &lt;code&gt;BlockValuesRefs&lt;/code&gt; object. These arrays are only referenced by the new
object, so we don't have to keep track of any other objects. The object creates a &lt;code&gt;weakref&lt;/code&gt; that points
to the &lt;code&gt;Block&lt;/code&gt; that wraps the NumPy array and stores this reference internally. The concept
of Blocks is explained &lt;a href="https://medium.com/better-programming/pandas-internals-explained-545f14a941c1"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;a href="https://docs.python.org/3/library/weakref.html"&gt;weakref&lt;/a&gt; creates a reference to any Python
object. It does not keep this object alive when it would normally go out of scope.&lt;/p&gt;
&lt;p&gt;```python
import weakref&lt;/p&gt;
&lt;p&gt;class Dummy:
    def &lt;strong&gt;init&lt;/strong&gt;(self, a):
        self.a = a&lt;/p&gt;
&lt;p&gt;In[1]: obj = Dummy(1)
In[2]: ref = weakref.ref(obj)
In[3]: ref()
Out[3]: &amp;lt;&lt;strong&gt;main&lt;/strong&gt;.Dummy object at 0x108187d60&amp;gt;
In[4]: obj = Dummy(2)
```&lt;/p&gt;
&lt;p&gt;This example creates a Dummy object and a weak reference to this object. Afterward, we assign another
object to the same variable, e.g. the initial object goes out of scope and is garbage collected. The weak reference
does not interfere with this process. If you resolve the weak reference, it will point to &lt;code&gt;None&lt;/code&gt;
instead of the original object.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
In[5]: ref()
Out[5]: None&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This ensures that we don't keep any arrays alive that would otherwise be garbage collected.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's take a look at how these objects are organized:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="../images/deep_dive_cow/copy-on-write.svg"&gt;&lt;/p&gt;
&lt;p&gt;Our example has two columns &lt;code&gt;"a"&lt;/code&gt; and &lt;code&gt;"b"&lt;/code&gt; which both have dtype &lt;code&gt;"int64"&lt;/code&gt;. They are backed
by one Block that holds the data for both columns. The Block holds a hard reference to the reference
tracking object, ensuring that it stays alive as long as the Block is not garbage collected. The
reference tracking object holds a weak reference to the Block. This enables the object to track
the lifecycle of this block but does not prevent garbage collection. The reference tracking object
does not hold a weak reference to any other Block yet.&lt;/p&gt;
&lt;p&gt;These are the easy scenarios. We know that no other pandas object shares the same NumPy array, so we can
simply instantiate a new reference tracking object. &lt;/p&gt;
&lt;p&gt;The third case is more complicated. The new object views the same data as the original object.
This means that both objects point to the same memory. Our operation will create a new Block that
references the same NumPy array, this is called a shallow copy. We now have to register this new 
&lt;code&gt;Block&lt;/code&gt; in our reference tracking mechanism. We will register our new &lt;code&gt;Block&lt;/code&gt; with the reference 
tracking object that is connected to the old object.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df2 = df.reset_index(drop=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt="" src="../images/deep_dive_cow/copy-on-write_view.svg"&gt;&lt;/p&gt;
&lt;p&gt;Our &lt;code&gt;BlockValuesRefs&lt;/code&gt; now points to the Block that backs the initial &lt;code&gt;df&lt;/code&gt; and the newly created
Block that backs &lt;code&gt;df2&lt;/code&gt;. This ensures that we are always aware about all DataFrames that point to
the same memory. &lt;/p&gt;
&lt;p&gt;We can now ask the reference tracking object how many Blocks pointing to the same NumPy array
are alive. The reference tracking object evaluates the weak references and tells us that more
than one object references the same data. This enables us to trigger a copy internally if one of 
them is modified inplace. &lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df2.iloc[0, 0] = 100
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Block in &lt;code&gt;df2&lt;/code&gt; is copied through a deep copy, creating a new Block that has its own data and
reference tracking object. The original block that was backing &lt;code&gt;df2&lt;/code&gt; can now be garbage collected,
which ensures that the arrays backing &lt;code&gt;df&lt;/code&gt; and &lt;code&gt;df2&lt;/code&gt; don't share any memory.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="../images/deep_dive_cow/copy-on-write_copy.svg"&gt;&lt;/p&gt;
&lt;p&gt;Let's look at a different scenario.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = None
df2.iloc[0, 0] = 100
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;df&lt;/code&gt; is invalidated before we modify &lt;code&gt;df2&lt;/code&gt;. Consequently, the weakref of our reference tracking
object, that points to the Block that backed &lt;code&gt;df&lt;/code&gt;, evaluates to &lt;code&gt;None&lt;/code&gt;. This enables us to modify 
&lt;code&gt;df2&lt;/code&gt; without triggering a copy.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="../images/deep_dive_cow/copy-on-write_invalidate.svg"&gt;&lt;/p&gt;
&lt;p&gt;Our reference tracking object points to only one DataFrame which enables us to do the operation
inplace without triggering a copy.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reset_index&lt;/code&gt; above creates a view. The mechanism is a bit simpler if we have an operation that 
triggers a copy internally.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df2 = df.copy()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This immediately instantiates a new reference tracking object for our DataFrame &lt;code&gt;df2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="../images/deep_dive_cow/copy-on-write_copy_immediately.svg"&gt;&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have investigated how the Copy-on-Write tracking mechanism works and when we trigger a copy. 
The mechanism defers copies in pandas as much as possible, which is quite different from the non-CoW 
behavior. The reference tracking mechanism keeps track of all DataFrames that share memory,
enabling more consistent behavior in pandas.&lt;/p&gt;
&lt;p&gt;The next part in this series will explain techniques that are used to make this mechanism more
efficient.&lt;/p&gt;
&lt;p&gt;Thank you for reading. Feel free to reach out to share your thoughts and feedback 
about Copy-on-Write.&lt;/p&gt;</content><category term="posts"></category><category term="pandas"></category><category term="copy-on-write"></category><category term="performance"></category></entry><entry><title>High Level Query Optimization in Dask</title><link href="https://phofl.github.io/high-level-query-optimization-in-dask.html" rel="alternate"></link><published>2023-08-04T00:00:00+02:00</published><updated>2023-08-04T00:00:00+02:00</updated><author><name>Patrick Hoefler</name></author><id>tag:phofl.github.io,2023-08-04:/high-level-query-optimization-in-dask.html</id><summary type="html">&lt;p&gt;&lt;img alt="" src="../images/dask-expr/dask-expr-introduction-title.png"&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Dask DataFrame doesn't currently optimize your code for you (like Spark or a SQL database would). 
This means that users waste a lot of computation. Let's look at a common example
which looks ok at first glance, but is actually pretty inefficient.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;import dask.dataframe as dd

df = dd …&lt;/code&gt;&lt;/pre&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="" src="../images/dask-expr/dask-expr-introduction-title.png"&gt;&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Dask DataFrame doesn't currently optimize your code for you (like Spark or a SQL database would). 
This means that users waste a lot of computation. Let's look at a common example
which looks ok at first glance, but is actually pretty inefficient.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;import dask.dataframe as dd

df = dd.read_parquet(
    &amp;quot;s3://coiled-datasets/uber-lyft-tlc/&amp;quot;,  # unnecessarily reads all rows and columns
)
result = (
    df[df.hvfhs_license_num == &amp;quot;HV0003&amp;quot;]    # could push the filter into the read parquet call
    .sum(numeric_only=True)
    [&amp;quot;tips&amp;quot;]                                # should read only necessary columns
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can make this run much faster with a few simple steps:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = dd.read_parquet(
    &amp;quot;s3://coiled-datasets/uber-lyft-tlc/&amp;quot;,
    filters=[(&amp;quot;hvfhs_license_num&amp;quot;, &amp;quot;==&amp;quot;, &amp;quot;HV0003&amp;quot;)],
    columns=[&amp;quot;tips&amp;quot;],
)
result = df.tips.sum()

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Currently, Dask DataFrame wouldn't optimize this for you, but a new effort that is built around
logical query planning in Dask DataFrame will do this for you. This article introduces some of
those changes that are developed in &lt;a href="https://github.com/dask-contrib/dask-expr"&gt;dask-expr&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can install and try &lt;code&gt;dask-expr&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;pip install dask-expr
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are using the &lt;a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page"&gt;NYC Taxi&lt;/a&gt; 
dataset in this post.&lt;/p&gt;
&lt;h2 id="dask-expressions"&gt;Dask Expressions&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/dask-contrib/dask-expr"&gt;Dask expressions&lt;/a&gt; provides a logical query planning layer on 
top of Dask DataFrames. Let's look at our initial example and investigate how we can improve the efficiency
through a query optimization layer. As noted initially, there are a couple of things that aren't ideal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We are reading all rows into memory instead of filtering while reading the parquet files.&lt;/li&gt;
&lt;li&gt;We are reading all columns into memory instead of only the columns that are necessary.&lt;/li&gt;
&lt;li&gt;We are applying the filter and the aggregation onto all columns instead of only &lt;code&gt;"tips"&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The query optimization layer from &lt;code&gt;dask-expr&lt;/code&gt; can help us with that. It will look at this expression
and determine that not all rows are needed. An intermediate layer will transpile the filter into
a valid filter-expression for &lt;code&gt;read_parquet&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = dd.read_parquet(
    &amp;quot;s3://coiled-datasets/uber-lyft-tlc/&amp;quot;,
    filters=[(&amp;quot;hvfhs_license_num&amp;quot;, &amp;quot;==&amp;quot;, &amp;quot;HV0003&amp;quot;)],
)
result = df.sum(numeric_only=True)[&amp;quot;tips&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This still reads every column into memory and will compute the sum of every numeric column. The 
next optimization step is to push the column selection into the &lt;code&gt;read_parquet&lt;/code&gt; call as well.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = dd.read_parquet(
    &amp;quot;s3://coiled-datasets/uber-lyft-tlc/&amp;quot;,
    columns=[&amp;quot;tips&amp;quot;],
    filters=[(&amp;quot;hvfhs_license_num&amp;quot;, &amp;quot;==&amp;quot;, &amp;quot;HV0003&amp;quot;)],
)
result = df.sum(numeric_only=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a basic example that you could rewrite by hand. Use cases that are closer to real
workflows might potentially have hundreds of columns, which makes rewriting them very strenuous
if you need a non-trivial subset of them.&lt;/p&gt;
&lt;p&gt;Let's take a look at how we can achieve this. &lt;code&gt;dask-expr&lt;/code&gt; records the expression as given by the
user in an expression tree:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;result.pprint()

Projection: columns='tips'
  Sum: numeric_only=True
    Filter:
      ReadParquet: path='s3://coiled-datasets/uber-lyft-tlc/'
      EQ: right='HV0003'
        Projection: columns='hvfhs_license_num'
          ReadParquet: path='s3://coiled-datasets/uber-lyft-tlc/'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tree represents the expression as is. We can observe that we would read the whole dataset into
memory before we apply the projections and filters. One observation of note: It seems like we
are reading the dataset twice, but Dask is able to fuse tasks that are doing the same to avoid
computing these things twice. Let's reorder the expression to make it more efficient:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;result.simplify().pprint()

Sum: numeric_only=True
  ReadParquet: path='s3://coiled-datasets/uber-lyft-tlc/' 
               columns=['tips'] 
               filters=[('hvfhs_license_num', '==', 'HV0003')] 

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This looks quite a bit simpler. &lt;code&gt;dask-expr&lt;/code&gt; reordered the query and pushed the filter and the column
projection into the &lt;code&gt;read_parquet&lt;/code&gt; call. We were able to remove quite a few steps from our expression
tree and make the remaining expressions more efficient as well. This represents the steps that
we did manually in the beginning. &lt;code&gt;dask-expr&lt;/code&gt; performs these steps for arbitrary many columns without
increasing the burden on the developers.&lt;/p&gt;
&lt;p&gt;These are only the two most common and easy to illustrate optimization techniques from &lt;code&gt;dask-expr&lt;/code&gt;. 
Some other useful optimizations are already available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;len(...)&lt;/code&gt; will only use the Index to compute the length; additionally we can ignore many operations
  that won't change the shape of a DataFrame, like a &lt;code&gt;replace&lt;/code&gt; call.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;set_index&lt;/code&gt; and &lt;code&gt;sort_values&lt;/code&gt; won't eagerly trigger computations.&lt;/li&gt;
&lt;li&gt;Better informed selection of &lt;code&gt;merge&lt;/code&gt; algorithms.&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are still adding more optimization techniques to make Dask DataFrame queries more efficient.&lt;/p&gt;
&lt;h2 id="try-it-out"&gt;Try it out&lt;/h2&gt;
&lt;p&gt;The project is in a state where interested users should try it out. We published a couple of 
releases. The API covers a big chunk of the Dask DataFrame API, and we keep adding more. 
We have already observed very impressive performance improvements for workflows that would benefit
from query optimization. Memory usage is down for these workflows as well.&lt;/p&gt;
&lt;p&gt;We are very much looking for feedback and potential avenues to improve the library. Please give it
a shot and share your experience with us.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;dask-expr&lt;/code&gt; is not integrated into the main Dask DataFrame implementation yet. You can install it
with:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;pip install dask-expr
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The API is very similar to what Dask DataFrame provides. It exposes mostly the same methods as
Dask DataFrame does. You can use the same methods in most cases.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import dask_expr as dd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can find a list of supported operations in the 
&lt;a href="https://github.com/dask-contrib/dask-expr#api-coverage"&gt;Readme&lt;/a&gt;. This project is still very much
in progress. The API might change without warning. We are aiming for weekly releases to push new
features out as fast as possible.&lt;/p&gt;
&lt;h2 id="why-are-we-adding-this-now"&gt;Why are we adding this now?&lt;/h2&gt;
&lt;p&gt;Historically, Dask focused on flexibility and smart scheduling instead of query optimization. 
The distributed scheduler built into Dask uses sophisticated algorithms to ensure ideal scheduling
of individual tasks. It tries to ensure that your resources are utilized as efficient as possible.
The graph construction process enables Dask users to build very
flexible and complicated graphs that reach beyond SQL operations. The flexibility that is provided
by the &lt;a href="https://docs.dask.org/en/latest/futures.html"&gt;Dask futures API&lt;/a&gt; requires very intelligent
algorithms, but it enables users to build highly sophisticated graphs. The following picture shows
the graph for a credit risk model:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="../images/dask-expr/graph_credit_risk_model.png"&gt;&lt;/p&gt;
&lt;p&gt;The nature of the powerful scheduler and the physical optimizations enables us to build very
complicated programs that will then run efficiently. Unfortunately, the nature of these optimizations 
does not enable us to avoid scheduling work that is not necessary. This is where the current effort
to build high level query optimization into Dask comes in.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Dask comes with a very smart distributed scheduler but without much logical query planning. This
is something we are rectifying now through building a high level query optimizer into Dask 
DataFrame. We expect to improve performance and reduce memory usage for an average Dask workflow.&lt;/p&gt;
&lt;p&gt;This API is read for interested users to play around with. It covers a good chunk of the DataFrame
API. The library is under active development, we expect to add many more interesting things over
the coming weeks and months. &lt;/p&gt;</content><category term="posts"></category><category term="dask"></category><category term="query optimizer"></category><category term="performance"></category></entry><entry><title>Dask performance benchmarking put to the test: Fixing a pandas bottleneck</title><link href="https://phofl.github.io/dask-performance-benchmarking-put-to-the-test-fixing-a-pandas-bottleneck.html" rel="alternate"></link><published>2023-06-28T00:00:00+02:00</published><updated>2023-06-28T00:00:00+02:00</updated><author><name>Patrick Hoefler</name></author><id>tag:phofl.github.io,2023-06-28:/dask-performance-benchmarking-put-to-the-test-fixing-a-pandas-bottleneck.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;Getting notified of a significant performance regression the day before release sucks, but quickly identifying and resolving it feels great!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We were getting set up at our booth at JupyterCon 2023 when we received a notification:
An engineer on our team had spotted a significant performance regression in Dask.
With …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Getting notified of a significant performance regression the day before release sucks, but quickly identifying and resolving it feels great!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We were getting set up at our booth at JupyterCon 2023 when we received a notification:
An engineer on our team had spotted a significant performance regression in Dask.
With an impact of 40% increased runtime, it blocked the release planned for the next day!&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="../images/dask_upstream_performance_tests/performance-regression.png"&gt;&lt;/p&gt;
&lt;p&gt;Luckily, the other attendees still focused on coffee and breakfast, so we commandeered an abandoned table next to our booth and got to work.&lt;/p&gt;
&lt;h2 id="performance-testing-at-coiled"&gt;Performance testing at Coiled&lt;/h2&gt;
&lt;p&gt;The performance problem &lt;a href="https://github.com/coiled/benchmarks/issues/840"&gt;had been flagged&lt;/a&gt; by the automated performance testing for Dask that we developed at &lt;a href="https://www.coiled.io/?utm_source=phofl&amp;amp;utm_medium=dask-benchmark-pandas-bottleneck"&gt;Coiled&lt;/a&gt;.
If you have not read Guido Imperiale's &lt;a href="https://blog.coiled.io/blog/performance-testing.html?utm_source=phofl&amp;amp;utm_medium=dask-benchmark-pandas-bottleneck"&gt;blog post&lt;/a&gt; on our approach to performance testing, here is a summary:
With &lt;a href="https://github.com/coiled/benchmarks"&gt;&lt;code&gt;coiled/benchmarks&lt;/code&gt;&lt;/a&gt;, we created a benchmark suite that contains a variety of common workloads and operations with Dask, including standardized ones like the &lt;a href="https://github.com/h2oai/db-benchmark"&gt;&lt;code&gt;h2oai/db-benchmark&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It also contains tooling that allows us to do two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatically &lt;a href="https://blog.coiled.io/blog/performance-testing.html#nightly-tests?utm_source=phofl&amp;amp;utm_medium=dask-benchmark-pandas-bottleneck"&gt;detect performance regressions&lt;/a&gt; in Dask and raise them as issues.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.coiled.io/blog/performance-testing.html#a-b-tests?utm_source=phofl&amp;amp;utm_medium=dask-benchmark-pandas-bottleneck"&gt;Run A/B tests&lt;/a&gt; to assess the performance impact of different versions of Dask, upstream packages, or cluster configurations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While the former started this journey, the latter will also come in handy soon.  &lt;/p&gt;
&lt;h2 id="identifying-the-problem"&gt;Identifying the problem&lt;/h2&gt;
&lt;p&gt;Our automated regression testing had alerted us that &lt;a href="https://github.com/coiled/benchmarks/blob/895a13db09eb3172155e7b1260a5698f2284f5b7/tests/benchmarks/test_h2o.py#L140-L151"&gt;&lt;code&gt;test_h2o.py::test_q8&lt;/code&gt;&lt;/a&gt; had experienced &lt;a href="https://github.com/dask/community/issues/322#issuecomment-1542560550"&gt;a significant increase&lt;/a&gt; in runtime across all data sizes and file formats. 
From the &lt;a href="https://benchmarks.coiled.io?utm_source=phofl&amp;amp;utm_medium=dask-benchmark-pandas-bottleneck"&gt;historical report&lt;/a&gt; of our benchmarking suite, we could see that &lt;code&gt;dask/dask&lt;/code&gt; and &lt;code&gt;dask/distributed&lt;/code&gt; were unlikely to be the culprit: 
Nothing had changed on &lt;code&gt;dask/dask&lt;/code&gt; when the performance started to degrade, and there was only one unrelated change on &lt;code&gt;dask/distributed&lt;/code&gt;. 
That left us with the Coiled platform and upstream packages as possible candidates. &lt;/p&gt;
&lt;p&gt;After digging deeper into the cluster data, we noticed that &lt;code&gt;pandas&lt;/code&gt; had been upgraded from &lt;code&gt;1.5.3&lt;/code&gt; to &lt;code&gt;2.0.1&lt;/code&gt;. 
A major upgrade to &lt;code&gt;pandas&lt;/code&gt; at the same time a dataframe-based workload shows degrading performance? That's suspicious! &lt;/p&gt;
&lt;p&gt;To confirm this suspicion, we ran an A/B test based on the current Dask release (&lt;code&gt;2023.4.1&lt;/code&gt; at the time), testing the impact of the pandas upgrade. 
&lt;a href="https://github.com/coiled/benchmarks/actions/runs/4946428740"&gt;The results&lt;/a&gt; were clear: The runtime increased significantly with &lt;code&gt;pandas=2.0.1&lt;/code&gt; (sample).&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="../images/dask_upstream_performance_tests/ab-test.png"&gt;&lt;/p&gt;
&lt;p&gt;Having shown that &lt;code&gt;pandas&lt;/code&gt; caused for the performance degradation and that we could reproduce it with the current Dask release, our release process for &lt;code&gt;2023.5.0&lt;/code&gt; &lt;a href="https://github.com/dask/community/issues/322#issuecomment-1543878628"&gt;was cleared&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To further analyze the problem, we also derived a &lt;a href="https://matthewrocklin.com/minimal-bug-reports.html#minimal-complete-verifiable-examples"&gt;minimal local reproducer&lt;/a&gt; from the original workload:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;from dask.distributed import Client

client = Client()
uri = &amp;quot;s3://coiled-datasets/h2o-benchmark/N_1e7_K_1e2_parquet/*.parquet&amp;quot;
ddf = dd.read_parquet(uri, engine=&amp;quot;pyarrow&amp;quot;, storage_options={&amp;quot;anon&amp;quot;: True}).persist()
wait(ddf)

ddf = ddf[[&amp;quot;id6&amp;quot;, &amp;quot;v1&amp;quot;, &amp;quot;v2&amp;quot;, &amp;quot;v3&amp;quot;]]
(
    ddf[~ddf[&amp;quot;v3&amp;quot;].isna()][[&amp;quot;id6&amp;quot;, &amp;quot;v3&amp;quot;]]
    .groupby(&amp;quot;id6&amp;quot;, dropna=False, observed=True)
    .apply(
        lambda x: x.nlargest(2, columns=&amp;quot;v3&amp;quot;),
        meta={&amp;quot;id6&amp;quot;: &amp;quot;Int64&amp;quot;, &amp;quot;v3&amp;quot;: &amp;quot;float64&amp;quot;},
    )[[&amp;quot;v3&amp;quot;]]
).compute()
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="investigating-the-pandas-performance-degradation"&gt;Investigating the pandas performance degradation&lt;/h2&gt;
&lt;p&gt;The only user-visible thing that changed between pandas 1.5.3 and pandas 2.0.1 was the default value
of &lt;code&gt;group_keys&lt;/code&gt; in &lt;code&gt;GroupBy&lt;/code&gt;. Switching to &lt;code&gt;group_keys=False&lt;/code&gt; with version 2.0.1
got us back to the initial runtime.
Now that we knew that pandas was to blame for the performance degradation, we had to create a 
reproducer in plain pandas to help fix the issue.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;df = pd.DataFrame(
    {
        &amp;quot;foo&amp;quot;: np.random.randint(1, 50_000, (100_000, )), 
        &amp;quot;bar&amp;quot;: np.random.randint(1, 100_000, (100_000, )),
    },
)

df.groupby(
    &amp;quot;foo&amp;quot;, group_keys=False
).apply(lambda x: x.nlargest(2, columns=&amp;quot;bar&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;group_keys=False&lt;/code&gt;: approx. 11 seconds&lt;/li&gt;
&lt;li&gt;&lt;code&gt;group_keys=True&lt;/code&gt;: approx. 15 seconds&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Experimenting a bit showed us that the bottleneck got even worse while increasing the number of 
groups during the &lt;code&gt;groupby&lt;/code&gt; calculation. We settled on this version which is 30% slower with 
&lt;code&gt;group_keys=True&lt;/code&gt;, enough to be able to troubleshoot the problem. There was no obvious reason
why the changed value should bring a significant slowdown.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;%prun&lt;/code&gt; showed us that the time was almost exclusively spent in a post-processing step that
combines all groups via &lt;code&gt;concat&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="addressing-the-performance-degradation"&gt;Addressing the performance degradation&lt;/h2&gt;
&lt;p&gt;Let's look at how both cases differ. The new version passes the grouping levels to &lt;code&gt;concat&lt;/code&gt;, which
are used to construct the resulting Index levels. This shouldn't be that slow though. Investigations
showed that this runs through a code-path that is very inefficient!&lt;/p&gt;
&lt;p&gt;Looking closer at the results of &lt;code&gt;%prun&lt;/code&gt; pointed us to one specific loop that took up most of
the runtime. This loop calculates the &lt;code&gt;codes&lt;/code&gt; for the resulting index based on the provided 
levels. It's slow, really slow! Every single element provided as &lt;code&gt;keys&lt;/code&gt;, which 
represent the number of groups, is checked against the whole level, which explains our previous 
observation that the runtime got worse with an increasing number of groups. You can check out the 
&lt;a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#more-concatenating-with-group-keys"&gt;pandas user guide&lt;/a&gt;
if you are interested in situations where this is useful. Fortunately, we have a convenient
advantage in case of &lt;code&gt;groupby&lt;/code&gt;. We know beforehand that every key equals the specific level. 
We added a fast-path that exploits this knowledge getting the runtime of this step more or less to
zero.&lt;/p&gt;
&lt;p&gt;This change resulted in a &lt;a href="https://github.com/pandas-dev/pandas/pull/53195"&gt;small PR&lt;/a&gt; that cut 
the runtime of &lt;code&gt;group_keys=True&lt;/code&gt; to approximately 11 seconds as well.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Now that we made our pandas reproducer run 30% faster, we have to check whether we accomplished our
initial objective. Re-running the local Dask reproducer should give us an idea about the
impact on Dask. We got the performance down to 22 seconds as well! Promising news that saved
our plans for the evening!&lt;/p&gt;
&lt;p&gt;Unfortunately, we had to wait until pandas 2.0.2 was released to run a proper benchmark.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="../images/dask_upstream_performance_tests/benchmark_after.jpg"&gt;&lt;/p&gt;
&lt;p&gt;This looks great! Our small pandas change translated to our Dask query and got performance back
to the previous level!&lt;/p&gt;</content><category term="posts"></category><category term="dask"></category><category term="performance"></category><category term="coiled"></category><category term="pandas"></category></entry></feed>