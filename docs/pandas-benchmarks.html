<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="https://phofl.github.io/theme/css/style.less">
  <script src="//cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="icon" type="image/vnd.microsoft.icon" href="https://phofl.github.io/">
  <link rel="stylesheet" type="text/css" href="https://phofl.github.io/theme/css/style.min.css">
  <link rel="stylesheet" type="text/css" href="https://phofl.github.io/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Roboto+Mono">
  <link rel="stylesheet" type="text/css" href="https://phofl.github.io/theme/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="https://phofl.github.io/theme/css/hatena-bookmark-icon.css">
  <link rel="stylesheet" type="text/css" href="/docs/extra/custom.css">


  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Patrick Hoefler">
  <meta name="description" content="Posts and writings by Patrick Hoefler">

  <link href="https://phofl.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Patrick Hoefler Atom" />

<meta name="keywords" content="pandas">

  <title>
    Patrick Hoefler
&ndash; Benchmarking pandas against Polars from a pandas PoV  </title>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'G-SE6TX73EFF']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<body>
  <main>
    <header>
      <div class="site-name">
        <a href="https://phofl.github.io">Patrick Hoefler</a>
      </div>
      <p>
        <a href="https://phofl.github.io/archives.html"><i class="fa fa-archive"></i> Archive</a>
      </p>
    </header>

<article>
  <div class="article__title">
    <h1><a href="https://phofl.github.io/pandas-benchmarks.html">Benchmarking pandas against Polars from a pandas PoV</a></h1>
  </div>
  <div class="article__meta">
    <p class="article__meta__post-date">Posted on: Tue 13 June 2023</p>
 Tags:
      <a href="https://phofl.github.io/tag/pandas.html">#pandas</a>    </p>
  </div>
  <div class="article__text">
    <p><em>Or: How writing efficient pandas code matters</em></p>
<h2 id="introduction">Introduction</h2>
<p>I've regularly seen benchmarks that show how much faster Polars is compared to pandas. 
The fact that Polars is faster than pandas is not too surprising since it is multithreaded while 
pandas is mostly single-core. The big difference surprises me though. That's why I decided to take 
a look at the pandas queries that were used for the benchmarks. </p>
<p>I was curious to find out whether there was room for improvement. This post will detail a couple 
of easy steps that I took to speed up pandas code. The pandas performance improvements are quite 
impressive!</p>
<p>We will look at the <code>tpch</code> benchmarks from
the <a href="https://github.com/pola-rs/tpch">Polars repository</a> with <code>scale_1</code> including I/O time. </p>
<p>Fair warning: I had to try this a couple of times since the API changed. You can switch to version 
0.17.15, if you encounter problems, that's what I used. Additionally, I am using the current 
development version of pandas because some optimizations for Copy-on-Write and the 
Pyarrow <code>dtype_backend</code> were added after 2.0 was released. The development version was also used 
to create the baseline plots, so all performance gains shown in here can be attributed to the 
refactoring steps. You can use this version starting from August at the latest!</p>
<p>I came away with one main takeaway:</p>
<ul>
<li>Writing efficient pandas code <strong>matters a lot</strong>.</li>
</ul>
<p>I have a MacBook Air with M2 processors and 24GB of RAM. The benchmarks are only run once in 
default mode. I repeated the calculations 15 times and used the mean as result.</p>
<h2 id="baseline">Baseline</h2>
<p>I ran the benchmarks "as is" as a first step to get the status-quo.</p>
<p><img alt="" src="../images/pandas_benchmark/baseline.png"></p>
<p>It's relatively easy to see that Polars is between 4â€“10 times faster than pandas. After getting 
these results I decided to look at the queries that were used for pandas. A couple of relatively 
straightforward optimizations will speed up our pandas code a lot. Additionally, we will get other
benefits out of it as well, like a significantly reduced memory footprint.</p>
<p>Side note: Number 8 is broken, so no result there.</p>
<h2 id="initial-refactoring">Initial refactoring</h2>
<p>One thing that stood out is that the whole parquet files were read even though most queries only 
needed a small subset. Some queries also did some operations on the whole dataset and dropped the 
columns later on. A filtering operation is slowed down quite a bit when performed on the full 
DataFrame compared to only a fraction of the columns, e.g.:</p>
<pre><code class="language-python">new_df = df[mask]
new_df = df[[&quot;a&quot;, &quot;b&quot;]]
</code></pre>
<p>This is significantly slower than restricting the DataFrame to the relevant subset beforehand:</p>
<pre><code class="language-python">df = df[[&quot;a&quot;, &quot;b&quot;]]
new_df = df[mask]
</code></pre>
<p>There is no need to read these columns at all, if they are not used somewhere within your code. 
Pushing the column selection into <code>read_parquet</code> is easy, since this is offered by PyArrow through 
the <code>columns</code> keyword.</p>
<pre><code class="language-python">df = pd.read_parquet(...)
df = df[df.a &gt; 100]
df[[&quot;a&quot;, &quot;b&quot;]]
</code></pre>
<p>This is rewritten into:</p>
<pre><code class="language-python">df = pd.read_parquet(..., columns=[&quot;a&quot;, &quot;b&quot;])
df = df[df.a &gt; 100]
</code></pre>
<p>I've also turned Copy-on-Write on. It's now in a state that it shouldn't have many performance 
problems while it will most likely give a speedup. That said, the difference here is not too big, 
since the benchmarks are <code>GroupBy</code> and <code>merge</code> heavy, which aren't really influenced by CoW. 
This was a quick refactoring effort that took me around 30 minutes for all queries. Most queries 
restricted the DataFrame later on anyway, so it was mostly a copy-paste exercise.</p>
<p>Let's look at the results:</p>
<p><img alt="" src="../images/pandas_benchmark/first_optimization.png"></p>
<p>The pandas queries got a lot faster through a couple of small modifications, e.g. we can see 
performance improvements by a factor of 2 and more. Since this avoids loading unnecessary columns 
completely, we reduced the memory footprint of our program significantly.</p>
<h2 id="further-optimizations-leveraging-arrow">Further optimizations - leveraging Arrow</h2>
<p>A quick profiling showed that the filter operations were still a bottleneck for a couple of queries. 
Fortunately, there is an easy fix. <code>read_parquet</code> passes potential keywords through to PyArrow and 
Arrow offers the option to filter the table while reading the parquet file. Moving these filters up 
gives a nice additional improvement.</p>
<pre><code class="language-python">df = pd.read_parquet(..., columns=[&quot;a&quot;, &quot;b&quot;])
df = df[df.a &gt; 100]
</code></pre>
<p>We can easily pass the filter condition to Arrow to avoid materializing unnecessary rows:</p>
<pre><code class="language-python">import pyarrow.compute as pc


df = pd.read_parquet(..., columns=[&quot;a&quot;, &quot;b&quot;], filters=pc.field(&quot;a&quot;) &gt; 100)
</code></pre>
<p>Arrow supports an Expression style for these filter conditions. You can use more or less all 
filtering operations that would be available in pandas as well. Let's look at what this means 
performance-wise.</p>
<p><img alt="" src="../images/pandas_benchmark/second_optimization.png"></p>
<p>We got a nice performance improvement for most queries. Obviously, this depends on what filter was 
used in the query itself. Similar to the first optimization, this will reduce the memory footprint 
significantly, since rows violating the filter won't be loaded into memory at all.</p>
<p>There is one relatively straightforward optimization left without rewriting the queries completely.</p>
<h2 id="improving-merge-performance">Improving <code>merge</code> performance</h2>
<p>This technique is a bit tricky. I stumbled upon this a couple of years ago when I had a performance
issue at my previous job. In these scenarios, <code>merge</code> is basically used as a filter that restricts
one of both DataFrames quite heavily. This is relatively slow when using merge, because pandas
isn't aware that you want to use the <code>merge</code> operation as a filter. We can apply a filter
with isin before performing the actual merge to speed up our queries.</p>
<pre><code class="language-python">import pandas as pd

left = pd.DataFrame({&quot;left_a&quot;: [1, 2, 3], &quot;left_b&quot;: [4, 5, 6]})
right = pd.DataFrame({&quot;right_a&quot;: [1], &quot;right_c&quot;: [4]})

left = left[left[&quot;left_a&quot;].isin(right[&quot;right_a&quot;])]  # restrict the df beforehand
result = left.merge(right, left_on=&quot;left_a&quot;, right_on=&quot;right_a&quot;)
</code></pre>
<p>This wasn't necessary for all queries, since only a couple of them were using <code>merge</code> in this way. 
The queries where we applied the technique got another nice performance boost!</p>
<p><img alt="" src="../images/pandas_benchmark/final_optimization.png"></p>
<p>We achieved our main objective here. Most of these queries run a lot faster now than they did 
before, and use less memory as well. The first query did not get that big of a speedup. It 
calculates a lot of results on a groupby aggregation, which is done sequentially. We are looking
into it right now how we can improve performance here.</p>
<h2 id="summary">Summary</h2>
<p>All in all these optimizations took me around 1.5-2 hours. Your mileage might vary, but I don't 
think that it will take you much longer, since most of the optimizations are very straightforward. 
A relatively small time investment where most
of the time was spent on reorganizing the initial queries. You can find the PR that modifies the 
benchmarks <a href="TODO: Add PR link">here</a>. Polars has a query optimization layer, so it does some of
these things automatically, but this is not a guarantee that you'll end up with efficient code. </p>
<p>We saw that writing more efficient pandas code isn't that hard and can give you a huge performance 
improvement. Looking at these queries helped us as well, since we were able to identify a couple of 
performance bottleneck where we are working on a solution. We were even able to make one of the 
queries run faster than the Polars version!</p>
<p>These performance improvements mostly translate to the <code>scale_10</code> version of the benchmarks.</p>
<p>Thanks for reading. Please reach out with any comments or feedback. I wrote a more general post about
<a href="https://towardsdatascience.com/utilizing-pyarrow-to-improve-pandas-and-dask-workflows-2891d3d96d2b">improving performance in pandas with PyArrow</a> 
as well.</p>
  </div>

</article>


  </main>
    <footer>
      <section class="author">
        <div class="author__name">
          <a href="https://phofl.github.io/pages/about.html">Patrick Hoefler</a>
          <p></p>
        </div>
        <div class="author__link">
          <ul>
            <li><a href="https://phofl.github.io/pages/about.html" title="About"><i class="fa fa-link"></i></a></li>
            <li>
              <a href="https://github.com/phofl/" target="_blank" title="github">
                <i class="fa fa-github-square"></i>
              </a>
            </li>
            <li>
              <a href="https://www.linkedin.com/in/patrick-hoefler/" target="_blank" title="linkedin">
                <i class="fa fa-linkedin-square"></i>
              </a>
            </li>
            <li>
              <a href="mailto:patrick_hoefler@gmx.net" target="_blank" title="mail">
                <i class="fa fa-envelope"></i>
              </a>
            </li>
            <li>
              <a href="https://phofl.github.io/feeds/all.atom.xml" target="_blank" title="Feed">
                <i class="fa fa-rss"></i>
              </a>
            </li>
          </ul>
        </div>
      </section>
      <div class="ending-message">
        <p>&copy; Patrick Hoefler. Powered by <a href="http://getpelican.com" target="_blank">Pelican</a>, Theme is using <a href="https://github.com/laughk/pelican-hss" target="_blank">HSS</a>. </p>
      </div>
    </footer>
</body>
</html>